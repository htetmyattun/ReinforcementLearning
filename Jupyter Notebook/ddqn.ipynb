{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial by www.pylessons.com\n",
    "# Tutorial written for - Tensorflow 1.15, Keras 2.2.4\n",
    "\n",
    "import os\n",
    "import random\n",
    "import gym\n",
    "import pylab\n",
    "import numpy as np\n",
    "from collections import deque \n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Lambda, Add\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OurModel(input_shape, action_space, dueling):\n",
    "    X_input = Input(input_shape)\n",
    "    X = X_input\n",
    "\n",
    "    # 'Dense' is the basic form of a neural network layer\n",
    "    # Input Layer of state size(4) and Hidden Layer with 512 nodes\n",
    "    X = Dense(512, input_shape=input_shape, activation=\"relu\", kernel_initializer='he_uniform')(X)\n",
    "\n",
    "    # Hidden layer with 256 nodes\n",
    "    X = Dense(256, activation=\"relu\", kernel_initializer='he_uniform')(X)\n",
    "    \n",
    "    # Hidden layer with 64 nodes\n",
    "    X = Dense(64, activation=\"relu\", kernel_initializer='he_uniform')(X)\n",
    "\n",
    "    if dueling:\n",
    "        state_value = Dense(1, kernel_initializer='he_uniform')(X)\n",
    "        state_value = Lambda(lambda s: K.expand_dims(s[:, 0], -1), output_shape=(action_space,))(state_value)\n",
    "\n",
    "        action_advantage = Dense(action_space, kernel_initializer='he_uniform')(X)\n",
    "        action_advantage = Lambda(lambda a: a[:, :] - K.mean(a[:, :], keepdims=True), output_shape=(action_space,))(action_advantage)\n",
    "\n",
    "        X = Add()([state_value, action_advantage])\n",
    "    else:\n",
    "        # Output Layer with # of actions: 2 nodes (left, right)\n",
    "        X = Dense(action_space, activation=\"linear\", kernel_initializer='he_uniform')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='CartPole Dueling DDQN model')\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=RMSprop(lr=0.00025, rho=0.95, epsilon=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, env_name):\n",
    "        self.env_name = env_name       \n",
    "        self.env = gym.make(env_name)\n",
    "        self.env.seed(0)  \n",
    "        # by default, CartPole-v1 has max episode steps = 500\n",
    "        self.env._max_episode_steps = 4000\n",
    "        self.state_size = self.env.observation_space.shape[0]\n",
    "        self.action_size = self.env.action_space.n\n",
    "\n",
    "        self.EPISODES = 1000\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01 # minimum exploration probability\n",
    "        self.epsilon_decay = 0.999 # exponential decay rate for exploration prob\n",
    "        self.batch_size = 32 \n",
    "        self.train_start = 1000\n",
    "\n",
    "        # defining model parameters\n",
    "        self.ddqn = True # use doudle deep q network\n",
    "        self.Soft_Update = False # use soft parameter update\n",
    "        self.dueling = True # use dealing netowrk\n",
    "\n",
    "        self.TAU = 0.1 # target network soft update hyperparameter\n",
    "\n",
    "        self.Save_Path = 'Models'\n",
    "        if not os.path.exists(self.Save_Path): os.makedirs(self.Save_Path)\n",
    "        self.scores, self.episodes, self.average = [], [], []\n",
    "        \n",
    "        if self.ddqn:\n",
    "            print(\"----------Double DQN--------\")\n",
    "            self.Model_name = os.path.join(self.Save_Path,\"Dueling DDQN_\"+self.env_name+\".h5\")\n",
    "        else:\n",
    "            print(\"-------------DQN------------\")\n",
    "            self.Model_name = os.path.join(self.Save_Path,\"Dueling DQN_\"+self.env_name+\".h5\")\n",
    "        \n",
    "        # create main model and target model\n",
    "        self.model = OurModel(input_shape=(self.state_size,), action_space = self.action_size, dueling = self.dueling)\n",
    "        self.target_model = OurModel(input_shape=(self.state_size,), action_space = self.action_size, dueling = self.dueling)\n",
    "\n",
    "    # after some time interval update the target model to be same with model\n",
    "    def update_target_model(self):\n",
    "        if not self.Soft_Update and self.ddqn:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            return\n",
    "        if self.Soft_Update and self.ddqn:\n",
    "            q_model_theta = self.model.get_weights()\n",
    "            target_model_theta = self.target_model.get_weights()\n",
    "            counter = 0\n",
    "            for q_weight, target_weight in zip(q_model_theta, target_model_theta):\n",
    "                target_weight = target_weight * (1-self.TAU) + q_weight * self.TAU\n",
    "                target_model_theta[counter] = target_weight\n",
    "                counter += 1\n",
    "            self.target_model.set_weights(target_model_theta)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if len(self.memory) > self.train_start:\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state))\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        # Randomly sample minibatch from the memory\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        state = np.zeros((self.batch_size, self.state_size))\n",
    "        next_state = np.zeros((self.batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        # do this before prediction\n",
    "        # for speedup, this could be done on the tensor level\n",
    "        # but easier to understand using a loop\n",
    "        for i in range(self.batch_size):\n",
    "            state[i] = minibatch[i][0]\n",
    "            action.append(minibatch[i][1])\n",
    "            reward.append(minibatch[i][2])\n",
    "            next_state[i] = minibatch[i][3]\n",
    "            done.append(minibatch[i][4])\n",
    "\n",
    "        # do batch prediction to save speed\n",
    "        # predict Q-values for starting state using the main network\n",
    "        target = self.model.predict(state)\n",
    "        # predict best action in ending state using the main network\n",
    "        target_next = self.model.predict(next_state)\n",
    "        # predict Q-values for ending state using the target network\n",
    "        target_val = self.target_model.predict(next_state)\n",
    "\n",
    "        for i in range(len(minibatch)):\n",
    "            # correction on the Q value for the action used\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                if self.ddqn: # Double - DQN\n",
    "                    # current Q Network selects the action\n",
    "                    # a'_max = argmax_a' Q(s', a')\n",
    "                    a = np.argmax(target_next[i])\n",
    "                    # target Q Network evaluates the action\n",
    "                    # Q_max = Q_target(s', a'_max)\n",
    "                    target[i][action[i]] = reward[i] + self.gamma * (target_val[i][a])   \n",
    "                else: # Standard - DQN\n",
    "                    # DQN chooses the max Q value among next actions\n",
    "                    # selection and evaluation of action is on the target Q Network\n",
    "                    # Q_max = max_a' Q_target(s', a')\n",
    "                    target[i][action[i]] = reward[i] + self.gamma * (np.amax(target_next[i]))\n",
    "\n",
    "        # Train the Neural Network with batches\n",
    "        self.model.fit(state, target, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model = load_model(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "\n",
    "    pylab.figure(figsize=(18, 9))\n",
    "    def PlotModel(self, score, episode):\n",
    "        self.scores.append(score)\n",
    "        self.episodes.append(episode)\n",
    "        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n",
    "        pylab.plot(self.episodes, self.average, 'r')\n",
    "        pylab.plot(self.episodes, self.scores, 'b')\n",
    "        pylab.ylabel('Score', fontsize=18)\n",
    "        pylab.xlabel('Steps', fontsize=18)\n",
    "        dqn = 'DQN_'\n",
    "        softupdate = ''\n",
    "        dueling = ''\n",
    "        if self.ddqn: dqn = 'DDQN_'\n",
    "        if self.Soft_Update: softupdate = '_soft'\n",
    "        if self.dueling: dueling = '_Dueling'\n",
    "        try:\n",
    "            pylab.savefig(dqn+self.env_name+softupdate+dueling+\".png\")\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "        return str(self.average[-1])[:5]\n",
    "    \n",
    "    def run(self):\n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "            done = False\n",
    "            i = 0\n",
    "            while not done:\n",
    "                #self.env.render()\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, self.state_size])\n",
    "                if not done or i == self.env._max_episode_steps-1:\n",
    "                    reward = reward\n",
    "                else:\n",
    "                    reward = -100\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                i += 1\n",
    "                if done:\n",
    "                    # every step update target model\n",
    "                    self.update_target_model()\n",
    "                    \n",
    "                    # every episode, plot the result\n",
    "                    average = self.PlotModel(i, e)\n",
    "                     \n",
    "                    print(\"episode: {}/{}, score: {}, e: {:.2}, average: {}\".format(e, self.EPISODES, i, self.epsilon, average))\n",
    "                    if i == self.env._max_episode_steps:\n",
    "                        print(\"Saving trained model as\", self.Model_name)\n",
    "                        #self.save(self.Model_name)\n",
    "                        break\n",
    "                self.replay()\n",
    "\n",
    "    def test(self):\n",
    "        self.load('ddqn.h5')\n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "            done = False\n",
    "            i = 0\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = np.argmax(self.model.predict(state))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                state = np.reshape(next_state, [1, self.state_size])\n",
    "                i += 1\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, i))\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Double DQN--------\n",
      "Model: \"CartPole Dueling DDQN model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          2560        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           16448       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            130         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2)            0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 150,531\n",
      "Trainable params: 150,531\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"CartPole Dueling DDQN model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          2560        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           16448       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            130         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2)            0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 150,531\n",
      "Trainable params: 150,531\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "episode: 0/10, score: 22, e: 1.0, average: 22.0\n",
      "episode: 1/10, score: 30, e: 1.0, average: 26.0\n",
      "episode: 2/10, score: 25, e: 1.0, average: 25.66\n",
      "episode: 3/10, score: 12, e: 1.0, average: 22.25\n",
      "episode: 4/10, score: 37, e: 1.0, average: 25.2\n",
      "episode: 5/10, score: 39, e: 1.0, average: 27.5\n",
      "episode: 6/10, score: 16, e: 1.0, average: 25.85\n",
      "episode: 7/10, score: 39, e: 1.0, average: 27.5\n",
      "episode: 8/10, score: 49, e: 1.0, average: 29.88\n",
      "episode: 9/10, score: 13, e: 1.0, average: 28.2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEOCAYAAACNY7BQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5K0lEQVR4nO3dd5xU9fX4/9dZFpYuIIjIoiCiiA6Kgj9UNLGARo0laiyxFz62n0pUYmLsicFeopAQS4zRqIloFI0Ne6xgoYgEVBARBSmKFIHd8/3jzHVml9kyuzPznnKej8d9vGfuzNx7dnZ3ztz7ft/zFlXFOeeci5SFDsA551x+8cTgnHOuBk8MzjnnavDE4JxzrgZPDM4552ooDx1AJnTt2lV79+4dOgznnCsoU6ZM+VpVu9VeXxSJoXfv3kyePDl0GM45V1BEZF6q9UETg4jMBVYAVcB6VR0sIl2Ah4DewFzg56q6LFSMzjlXavKhj2EvVd1RVQfH718MTFLVfsCk+H3nnHM5kg+JobZDgHvjt+8FDg0XinPOlZ7QiUGBZ0VkioiMjK/rrqoLAeLtJqleKCIjRWSyiExevHhxjsJ1zrniF7rzeXdV/UJENgGeE5GPGvtCVR0PjAcYPHiwF3xyzrkMCXrEoKpfxNtFwKPALsBXItIDIN4uChehc86VnmCJQUTaiUiH6DYwApgOPA6cGH/aicC/w0TonHOlKeQRQ3fgNRH5AHgbeFJVnwbGAMNFZDYwPH7fOefyQnU1/PSn8MILoSPJnmB9DKr6CbBDivVLgH1yH5FzzjVs1CiYOBHWrIG99w4dTXaEHpXknHMF49NP4Y9/tNutW4eNJZs8MTjnXCP95CegCttsA9Onh44mezwxOOdcI9x6K8yaBUOGwAknwNy5sGJF6KiywxODc841YPlyGD0aysutfyEWs/XFetTgicE55xpwyCGwdi1ccQVsskkiMUybFjSsrPHE4Jxz9Xj8cXjlFejdGy65xNZtsQV06OCJwTnnSs769XDccSBip5AiIrD99p4YnHOu5Jx4onUwn3IKbLddzcdiMUsMWoSV2jwxOOdcCu++Cw88AJ06wfjxGz4ei8HSpbBwYc5DyzpPDM45l8LBB1v78MNQluKTspg7oD0xOOdcLZdcAgsWwPDhtqQSJYapU3MXV654YnDOuSQLFsC110JFBUyYUPfzunSBzTYrziOG0BP1OOdcXjngAKiqgrFjoX37+p8bdUAXGz9icM65uLvuslNDsRiMHNnw82MxmDnThrUWE08MzjkHrFoF55xjHc1PPdW418Ri8P33MHt2dmPLNU8MzjkH/OxnNsfC6NFQWdm41xTryCRPDM65kjdpEjzzjHUm/+EPjX/dtttCixaeGDJORFqIyHsiMjF+/woRWSAi78eXA0LH6JwrXtXVcOSRdvvfac4w37o19OtXfIkhH0YlnQfMBDomrbtZVW8IFI9zroSccQYsWwZHHw2DB6f/+lgMpkzJfFwhBT1iEJFK4EDgzpBxOOdK08yZcOedVin1vvuato1YDD75BL77LrOxhRT6VNItwGigutb6c0RkqojcLSKdcx+Wc64UHHSQFcG77z6bhKcpog7oGTMyF1dowRKDiBwELFLV2gdh44C+wI7AQuDGOl4/UkQmi8jkxYsXZzVW51zxGTPGvukPG2YT8TRVMY5MCnnEsDtwsIjMBR4E9haRv6vqV6paparVwF+AXVK9WFXHq+pgVR3crVu33EXtnCt4X38Nl14KLVvCE080b1t9+kC7dp4YMkJVf62qlaraGzgaeEFVjxORHklPOwwo0llVnXOhHHSQXa183XVWVrs5yspsroZiSgz5MCqptutEZEdAgbnA/wWNxjlXVB5+GN56y4aZnn9+ZrYZi9lQV1Wb3a3Q5UViUNWXgJfit48PGoxzrmitXWuzsYnAf/6Tue3GYlZn6auvYNNNM7fdUEKPSnLOuZw55hhYuRLOPhv69s3cdoutA9oTg3OuJLzxhs2v0LUr3HprZrfticE55wpMdTUceqjdfuSR1FN1Nke3btC9uycG55wrGBddBIsW2WikPffMzj6KadIeTwzOuaI2bx7ccgu0aQP//Gf29hOL2dXPVVXZ20eueGJwzhW1n/zETiWNH2/VULMlFrP5HD7+OHv7yBVPDM65onX77VYob+ed4bjjsruvYuqA9sTgnCtK334LF1xgE+lMnJj9/Q0YYNdHeGJwzrk8dcghdkHbpZfm5qKztm1hq608MTjnXF6aOBFeegk23xwuvzx3+y2WkUmeGJxzRWX9evjFL+y0zpNP5nbfsRjMmQOrVuV2v5nmicE5V1ROOcX6F048EbbfPrf7jsWskN6HH+Z2v5nmicE5VzTef99mY+vUyYra5VqxjEzyxOCcKxoHH2ztgw9mvuxFY/TtaxfSeWJwzrk8cNllMH8+7LMP7LdfmBhatLBhq54YnHMusC+/hGuugYoKeOyxsLEUw8gkTwzOuYJ3wAFWo+jWW6F9+7CxxGI2Yc/ixWHjaA5PDM65gnbvvfDeezbv8v/lwUTAxdABHTwxiEgLEXlPRCbG73cRkedEZHa87Rw6Rudcflq1Cs44wzqan3oqdDTGE0NmnAfMTLp/MTBJVfsBk+L3nXNuA0ceaRVNL7jArnLOB9272yxxnhiaSEQqgQOBO5NWHwLcG799L3BojsNyzhWAl16yo4RNN4UxY0JHkyBS+B3QoY8YbgFGA9VJ67qr6kKAeLtJqheKyEgRmSwikxcXci+Pcy5t1dVwxBF2+/HHw1yzUJ9o0p7q6oafm4+CvZ0ichCwSFWnNOX1qjpeVQer6uBu3bplODrnXD475xxYssSSw5AhoaPZUCwGK1fCp5+GjqRpQubZ3YGDRWQu8CCwt4j8HfhKRHoAxNtF4UJ0zuWb2bPhT3+Cdu3g/vtDR5NaoXdAB0sMqvprVa1U1d7A0cALqnoc8DhwYvxpJwL/DhSicy4PHXCAFar761+hVavQ0aS23XbWemLInDHAcBGZDQyP33euJK1bZ2P0nfntb62s9a67JvoY8lH79rDlloWbGMpDBwCgqi8BL8VvLwH2CRmPcyF9/TUceii8+aZdzQs2b3H//kHDygvXXGOjfnIxVWdzFfLIpHw8YnCu5EyfDttua6NrunWD//43kRQARo0KF1u+ePRRO4U0YAB06RI6mobFYtYfsmZN6EjS54nBuUD+8x+orEyMe//oI/vgE7HyzW+8AR98YM999dWwseaD66+3Nh/KXjRGLGbJfebMhp+bbzwxOJdD48bZt10R60RdsMDWl5XBTjvBvHk29n3OHBg6FAYOtOeuXBk27nzw/vvWnnVW0DAarZBHJnlicC7LLrzQhlaK2IfasmW2vmVLmzdg5Ur7ZjllSuqyDtFpk3/9K3cx55vVq23p2NHmPCgE/fpZGXBPDM451q2zGj4VFZYMbrwxMTl869Zw2mmwdq0tTz8NbdvWv71jjrH2ssuyG3c++93vrN1tt7BxpKO83PqNPDE4V6K+/hqGDbMPg1at7Nv92rX2WMeO9sGmat96//IXO1porOjc+v/+l/m4C8UDD1h7+eVh40hXoY5M8sTgXBPNmmUjZFKNJNpkE5t3WBW++QYuuaTp+2nd2k6fVFUV5giXTJg/397noUNDR5KeWAy++AKWLg0dSXo8MTiXhueeg1697BRR//424iQaSdSnj40kUrUZvI46KnP73Woray+6KHPbLBTTp1tS7NEjdCTpK9QOaE8MzjUgeSTRiBHw+ee2vqwMBg1KjCT65JPsfaO94gprH3wwO9vPZ5deau3hh4eNoyk8MThXRD76yE7hpBpJNGJEYiTRu+/mZoKYo4+2dsmS7O8r37z8srVRciwkm20GnTt7YnCuKAwdCt9/b7dbt4aTT06MJHrmmYZHEmVDu3Z2mmrGjNzvO5SqKkvKFRX2AVtoCnXSHk8MzqXwzTfWrlhhI4nuvju9kUTZsOee1p59dtg4cikqqz1gQNg4miMWs34S1dCRNJ4nBudqiYaZglXJzBdjx1r71lth48ilW26x9vzzQ0bRPLGYfcGYNy90JI3nicG5WqKCdW3ahI2jtt697dREKQ1Z/fBDa487LmwczVGIHdCeGJyr5W9/s/bAA8PGkUr37taOHx82jlxYutT6eTp3zr85ndOx/fbWemJwroB99521+Tht5CmnWHvttWHjyIUrr7T2xz8OGkazdewIW2zhicG5gpXcv5CP00ZGH5Zz5wYNIyceecTaq64KG0cmFNrIJE8MziU580xrQwxHbYzychsdVV2dOLIpVgsXWimQ6FRMIYvFrIRK8hePfBYsMYhIaxF5W0Q+EJEZInJlfP0VIrJARN6PLweEitGVnocesjafr7KNhm4WyrwETfHmm5b8evUKHUlmDBwI69fbhZOFIOQRw/fA3qq6A7AjsL+IRAUFblbVHePLU8EidCUnmhDnzjvDxlGfqNrqE0+EjSOboqucjz02aBgZU2gjk8pD7VhVFYgOhlvGlwK6BMQVm3zvX4gMH27t8uVBw8iqN96w9re/DRtHpmy9tZ0CLJTEELSPQURaiMj7wCLgOVWNLt05R0SmisjdIpLyQngRGSkik0Vk8uLFi3MVsitiJ59sbbt2YeNojI4drX3ttbBxZENVFXz7rV1Hkm/XkjRVy5aFNWlP0MSgqlWquiNQCewiItsD44C+2OmlhcCNdbx2vKoOVtXB3bp1y1HErpg99pi1hXD6YsQIa3/5y7BxZEN0hfeOOwYNI+MKaWRSXoxKUtXlwEvA/qr6VTxhVAN/AXYJGZsrHdH0m7ffHjaOxhg3ztoPPggbRzb8+c/Wjh4dNo5Mi8VswqFCOAXYpMQgIn1E5DQRuUREesfXtRKRzUWkUWdnRaSbiHSK324D7At8JCLJ03EcBkxvSozOpaNQ+hciXbva1cBr19pol2ISTWF66KFBw8i4qAN6egF8oqWdGETkWuB/wHjgKmDL+EOtgQ+Bxg6i6wG8KCJTgXewPoaJwHUiMi2+fi9gVLoxOpeuaLa1Dh3CxpGOnj2tveGGsHFk0oIFsG6dJb5iU0gjk9JKDCLyf8BFwB3ACECix1T1W+Bx4KeN2ZaqTlXVQao6UFW3V9Wr4uuPV9VYfP3BqrownRida4qnn7b21FPDxpGO886z9o47wsaRSZddZu1++4WNIxsqK2GjjQojMYimUSRcRD4A5qjq4SKyMbAY2FdVX4g/fjFwjqpWZiXaOgwePFgnT56cy126IiPxrziFVDMfLG4RuxisGGy6qc2X/cknNod2sdljD2tffTVsHBERmaKqg2uvT/dU0tbAc/U8vhgowoNAV8wKubRERYUlsy+/DB1JZixaZGU/ijEpQGJkUr5/AUk3MawB6hvlvQWwvMnROBfAz39u7UYbhY2jKQYNsrYYymM8+6x9YG65ZcPPLVSxmM0O+PnnoSOpX7qJ4W1spNAGRKQ1cDzw3+YG5VwuvfCCtYU4ZeZtt1n7XH3H8QXi97+3NiotXowKpQM63cRwPbCriNwHDIyv21RE9sOuQ6gEimiMhCsF339vbfTBVEiGDLG2kE+HRaJuwlFFPA6xUCbtSSsxqOrzwJnAEcDz8dX3AU8BOwCnq+obGY3QuSxaujR0BM3XOV40ZuLEsHE0x9q1doFhu3aFcR1JU3XqZBVjiyoxgJWiAPoA52PlK/4MXAhspap/zWRwzmVb1L/QOWVFrsIQXQj2m98EDaNZrrvO2l1KoM5BIZTGaHR1VRFpD9wG/EdV/wn8MWtROZcj0bDBCy4IG0dz3HYb3HMPzJwZOpKmu/deay+9NGwcuRCLWZ/QunVWXC8fNfqIQVW/A44GOmYvHOdyKyqFccklYeNojvbtbaaz9esLtzzG3Ll2PcZee4WOJPtiMUsKUemPfJTuqaQPgd5ZiMO5nCuWsf+QGPdfiAnu448toW26aehIcqMQRialmxiuA84Uka2zEYxzuXTEEdZuvHHYODLh4outjU7JFJIomf20UcV0Cl///nYRXz4nhnRncOsPzAemichEYDawqtZzVFWvzkRwzmXT229bG32oFrJTT4XTTrMrhwvN8/Hxjb/7Xdg4cqVVK9hmm/xODOnWSmpMRRZV1RZNDyl9XivJNUWh1keqS9u2sHo1zJ4NW20VOprGE7EPy+h6klJwzDHw5pvw6adh48hUraQ+jViK+IJ2Vyw++yx0BJk3dKi1hXQF9z//ae3WJXZyOhazDvcVK0JHklpap5JUdV62AnEul4480tpNNgkbRyaNG2fnrwtpHuhoLoliqPWUjuRJe3bdNWwsqTR5ak8R2VhEBseXIui+c6Xk3XetvfLKsHFk0jbb2GmZVbV7/fLY1KnWjhwZNo5cy/eRSU2ZwW0HEXkZWAS8FV8WichLIjKw/lc7lx+i8f5nnBE2jkyLZj574IGwcTTGd9/BmjXQsaNdh1FKttjCZgssisQgItsDrwG7YbO1XRNf/g3sDrwqIttlOkjnMmnOHGujzudicuyx1hbCkdDV8bGLw4aFjSMEESuoVxSJAZvjeR2wk6oepqqXxpefAYOAqvhzGiQirUXkbRH5QERmiMiV8fVdROQ5EZkdbwu4io3LR1F9pO7dw8aRDdE5+48/DhtHYzz0kLVXNeoTo/jk86Q96SaGPYE7VHWDPKeq04GxwI8aua3vgb1VdQdgR2B/ERkKXAxMUtV+wKT4/aK2dGlpDdULLfqWFhVuKybl5bZUVdlpmnw2fz6UlcHOO4eOJIxYzP73F+bhrPbpJoZ2QH2FBBZS/wxvP1ATVZFvGV8UOASIrt+8Fzg0zRgLyrRpduVt69al1wEXStS/cPzxYePIlm22sTaf5zV4/32bp7pnz9CRNMGXX9qY4AceaFZxqnzugE43MXwCHFTP4wfFn9MoItJCRN7HOrKfU9W3gO6quhAg3qYcUCgiI0VksohMXrx4cWN3mXcGJnXX/+UvsNlm4WIpBdEomGLsX4hEp2YefjhsHPW5/HJro7IkeW/9erj1VrtysEcPGDsWfvEL+1Z36KFw++3w0UdpnRfK58SAqjZ6AX4FVAMPANsBLeLL9sD9WB/DRelsM77dTsCL8e0sr/XYsoZev/POO2shatFC1f6SVHfbLXFbRHX16tDRFaftt7f3uGfP0JFkV/S3lK822sjiW748dCQNeO011b32Ui0vT7yp22yj+sc/qj70kOrIkapbbpl4rLJS9aSTVP/+d9WFCxvc/GabqZ5wQg5+jjoAkzXVZ3KqlXUt8STwUDw5VGEd0evit6uBB4GydLaZtO3LsQl/ZgE94ut6ALMaem0hJoatt078LU2dauvGj0+sA9WnngobYzGKkvHDD4eOJLvatbOfc8qU0JFsaP16i62iInQkdVi8WPWMM1Q7d078M3bubOsWL079mo8/Vv3zn1WPPFK1S5fE62Ix1VGjVJ98UnXFig1ett9+qoMGZfnnqUdGEsMPL4LhwB3YlJ7/AW4H9k1zG92ATvHbbYBXsVNR1wMXx9dfDFzX0LYKLTFcemni7+ass2o+tmyZHTFEjx98cJAQi1a+f5POlIMOsp9z2LDQkWzozjsttrz6t62qUv3Tn+xoIPojKS+3o4XXXktvW+vXq06erDpmjOq++1oGBNWWLVX33FP1qqtUX39ddd06vfBCe3jduuz8WA3JaGLIxAIMBN4DpgLTgcvi6zfGRiPNjrddGtpWISWGzz9P/N3VdzojOtSOvqy45nvnHf3hVF2xmz/fftbWrUNHsqEddrDY7r8/dCSq+vbbqiNG2Id29A/Xt6/qLbdk7tN61SrV555T/dWvLBtG3/w6dtR7B92soDrzqU9Uq6szs7801JUY0q2u2gWoVNWpdTw+EJivqssavdEMKKTqqlGnp4iNyqjPQQfBk08mnr90qU0m7pqmf3+YNcuuOp07N3Q02VdWljgxmU8qKmzmvGBxLV9uvd/33w9Llti6jTaCww+32t89emR3/19/DS++CM8/z3sTF7DTFxN5mCM5svJN2HdfGD4c9tknJxfa1FVdNd1v+XcC79bz+BTgT+lsMxNLoRwxtGqV/qmMp55KvAasH8I1TVmZvYdPPBE6ktzYbDP7eW+7LXQkCUuWWExduuR4x1VVqnffrbrddolv7C1aqO6xh+qkSTkOJmH1atUWLar10gMnqx5xROr+iaeeStk/kQnUccSQ7nDVvYAn6nn8cWDfNLdZEgYPTswvHE1A3xg/+YnV2I+ONEaOhN13z3x8pSA6QjuovgHXRSS6LubGG8PGkeyyy6zde+8c7XDqVDjwQJus4pRTYMYMO2S89lq7AvCVV3IYzIZat4Z+/YRpLXe2GuSLFsHkyTBmjJX+HTsWDjgAunSBH/3I6oi8+Wb2J/dOlS3qWoDVwKn1PH4qsCqdbWZiyfcjhrFjE18Cjjqq6dvp0SOxnbZtMxdfKXj5ZXvfyspCR5I769bl388cHcV8+GEWd7JiheqFF6puskniH6Z9e9Xjj1edNy+LO26aI4+0bo2Uov6J0aNVd9qpRv+EHnKI6u23q37xRZP3TYaGq34NXFXP41fRiOsOMr3kc2KIDp0zdfh8+uk1Ty0142+ipGy1lf7Qr1hKoj7VZctCR2JE7AxOVjzwgOrAgYkPz7Iy1aFD837c91VXWcjffdeIJy9ebNdPnH66au/e9nM++2yT911XYkj3VNJbwIki0qH2A/F1JwBvN+3YpTglTzQf9XM1x/jx8NZbifubbVa6RcjS8Un8evzx48PGkWvR1bX5MKvbK6/Y15nevTO40Zkz4bDDoE0bKy07dSpUVtopl9Wr4Y037HxsHovF7H2ZMaMRT+7a1apAjh9v84J+/DHssUfGY0o3MdwAVAKvi8gRIrKViPQVkSOA1+OPXZ/pIAtVh6T0mcnJU3bZxf6QyuPz711+OQwYkLntF6OofyHg6eQgbr7Z2okTw8YBiTLbv/hFMze0ahVccol9KxowAB57zIZgHXWU1VT/7DP47W9tIukC0KzSGFtuaR0VGZZWYlDVF4GzgH7YFdCzgP8BD8fXnaOqz2c6yEK07742EQnAhAn2hSbT1q1LzJU7c2bB/B/k3DPPWFvW5PkKA3noIejc2WaxicXsDylNe+5p7bffZji2JnjzTWsvbkq95KlTrbBS167Qvj1cc40Vs9t5Z3tfVq6EBx+Evn0zGnMu9OkD7drlWc2kVOeXGlqAnsAo7OrnscB5QM+mbCsTS771MUyYkOgD2Gef7O8v+UpqUH3vvezvs5BEp2K33jp0JI3w0UeqffrU/IXWXlq3Vt11V9VXX23UJjt2tJe9/HKWY69HVAajTZtGvmDePNWTT7YRF9E442hp1071t79VXbkyqzHn0i67qO69d+73SzaufAbKsdncjgS2a862mrPkU2JYtSrx99u+fe72++mnNf93zjwzd/vOd9Hnyuuvh46kDitXqv7oRzVroUQlGY4/3kbZnH66ateuGz4n+qDcbz9LKikcfbQ9baedcvtjJbvxRoth993reMKSJTZmv3fvmtUlo+sNtthC9dxzVRctymXYOXPqqfbrzfXFz01ODMCPgduATWut7w18gBXQi5a7G9peNpZ8SgzJf88htGmT2H9lZZgY8k3e1kc6//yaVz1G9Tp23rn+sqPz56sefnjNuinJS6dOqj//+Q/VPZcts9UtW+bkp0qpf3+teXHhmjWqV19tDySXo4hGE226qZUdnTMnXNA5dMst9qM3oiBrRjUnMfwVmJdi/StYRdVXsU7pafHkcGJD28z0ki+JIfmixSVLwsWx6641/8dKuYT3o48m3oe88I9/pP5A32wz1TffbNo2p02zYm1RSdXaiaZbN92ErxSqgxVrKy+v1tastlKirVtvGGeXLqqHHmrF50rQpEna3JGnTdKcxDADuL3Wuv7xpPBS0ro2wEfYtJwllxiOOirxNz52bOhoVO+4o+b/XZ4P5c6aykr7+bfbLmAQdfUbtG9vFyhl2qRJdtI66QP4T4xUUH2TXexNueKK7Jf0nDBBddgwXdZmU61gtY7ixsTP3rGjdcA9/XR2YygQixbZ23Ljjbndb3MSw1Lg3FrrzogfHRxXa/1lwOKGtpnpJXRiePXVxN97HuSoH9Qu4f2zn4WOKPein/+DD3K845UrrcRy7T6Bli1VTzwxt7E88IA+0/0XCqpjuKhmPC1aqPbrpzpuXPP38/LLqvvvb6eykvbxBAcqqF7bdYxNYLN+ffP3VYS6d7c5fnKpOYlhJXB6rXV3xRNDr1rrTwbWNrTNTC+hE0P0P9CqVdAw6pR85iLnxcsCy3n/wrnnpu43GDIk+HRlFkq16k032RFM7U7eKHHtsIPqY481vMFp06wvI1WneEWFFYG7+WbdpFu1Ql5Wo8gr++6b+y+WdSWGxozs/gybxjPZMGCRqs6vtb4tsLwR2ywayWPjv/++CRuYNs0q5CUvZWV29Vrr1lZnu2dPGDQIDjnEqpC9nd7F5cuXJy7+XLrUNr9mTRNiLTD33WdtdCFg1tx/v5VtFoHbbktUS+zZ035X1dXWbrRRlgOpX0UFqAqfHznKLgVfv94uhhk92i4WKyuz+x98YPMYi9gFOHvsYVcQL1hglfkqKxPXVjz8sJWRbtEC+vWzC8tWrLA/sKlT4fzzWfy1UF4Om28e9MfPe7GYXf1cVRU6Ehp1xDAeO50Ui98/DOtf2GAEEvAn4L2GtpnpJdQRQ8+eiS9In3/ehA1svvmG39gyvUTFaSoqdE7rbbUX8+wUL8v03wePU33rrYy/L/kiKti2ww5Z2PhHHyUukKjdb5APnUwpDBtmIdY7K+CyZXY+Y+ONUw+NTR7V0KuX6tln1zuE9Ikn7On9+2f8xyk6d99t79WsWbnbJ804ldQHO51UBSyKt2uodd0CNh/0F8AfG9pmppcQieGssxL/I5demuaLo7kNU52DWrjQ/kJOOcVqxffta/+kbdvaYX5ZWf3/sA0s1aA3c562YJ1uw0z9kP4bPu/3v8/oexVK9DbNmJGhDa5cab+TfOg3aIIpUyzcdu3SeNFnn9looY4d7W/w2GPT+uSKktENN6Qfb6mJZhj8179yt88mJwZ7LYOxeRhmAhOBoSmesy82ZLVRcz8DvYAX49ucAZwXX38FsAB4P74c0NC2cp0Ypk5NfCakfTVt8oUGkN1vl/UkmWsYrW35TluxRv/A6NTfCCdMyF5sOZCx/oWzz95wrH2e9BukK9d9LtGfu/c3N2zlSvuzuvzy3O2zWYkhGwvQA9gpfrsDVnNpQDwxXJjOtnKdGJIHdDTaySfX/GDp0SNr8TXWKafUDGnhQrVvh7W/DWfsK3fujB9v4ZeXN3EDjz6aerx9z542T3CBiq61eeSR7O8rqgKQywoAha5fv9yOHqwrMQQrK6aqC1X13fjtFdiRQ89Q8TRWy5aJ242aRCnq7b3nnsS6qVPhiy8yHlu67rqrZgnvHj3g+t0etY/AqOTjunWw3XZWKjYfKrE10qWXWjtoUJovHDPGOlIPOyzRQ9++vc2kpQqffw5DhmQ01lw6/HBro5nUsum666wdOjT7+yoWsVieFNNLlS1yvWDlNT4DOmJHDHOBqcDdQOc6XjMSmAxM3nzzzbORTDewzTaJL45TpzbiBTvsUPPbZp2FYsIrL09xmmHNmpqzYIF1mBeAKNxGD5GsffgEYaqaZdnq1c08kkpD3762r5DF+wrN5Zfb6aRc1Qck344YIiLSHngEOF9VvwXGAX2BHYGFQMoZa1V1vKoOVtXB3bp1y3qcV10Fs2bZ7ZEjE1+oU5o0yYb6ffCB3W/RwmrIv/Za1uNsqnXrErd/mBO5ogK++srmoY3qhn/2mf1sBTLxdINDJH/8Y/t57r47se700y01TJqUzdCCaN3a/hzXr8/+tMFz59pbG5X+dg2LJu358MOwcQRNDCLSEksK96vqBABV/UpVq1S1GvgLsEvIGMGGb19+ud3u0QP+/Od6ntyli03GEBk92v4DszEhQ4Zde621Tz5Z64Fu3Syxvf22faoAvP66/defckpOY2yMaHKa5NN+NaxdaxNZiMDLL9u6sjK4/nr7ryzyad6iKQt+9avs7WPmTBuP36NH9vZRjJo1aU8GBUsMIiLYFdQzVfWmpPXJf0qHAdNzHVttlZXWitTTNXDllfaEZcvsfocO9iETfdoWgNGjE7ePOy7FE4YMsSSX3F9yzz32c990U4oXhPH731u7QVfA0qWW5CoqYPZsW9eyJTzxhH2KXXhhTuMM5ZJLrI0uAMyGqA/jkEOyt49i1LevfYcMnRhC9isMAxTrS3g/vhwA3IcNe50KPA70aGhb2RyVVFGROOW8alWKJ6xaVfMEPRT0MM9f/zpFX0NdRo2q+XOXleVFUbQao6xUrVBS27Y1Y23fviBHW2VKNOI2W6LRT0U6fUJW7byzlcfIBfJtuGoml2wlhiFDEp8jzz+f4gkjRtT8sCmSyzujH6fRk/385Cc134eWLW3OgEB+SGwPP7xh0u7ePWxN9DwRXV9Qx9w+zQb5Wzss3510kv2Z5kJdiSF453O+uusueOcdu33EEbDPPkkPzpljp0+efdbui9gwxpkzcx5nNpx5prXjxjXyBU89ZR+7/fvb/XXroFcvq/PUpAJSTRedRjqVv8DPf57oYd1uO4vlyy+tH6jE7bGHtWefnfltP/CAtdtum/ltl4JYzMZ8LF4cLgZPDCmsXg2nnWa3O3eGf/4z6cEttrBiYZEjjrAiaT3z/hKMRhs7NnH7N79J44UzZ9rY/+iD95tvbBhMriZoP+EEyn5rM83/H/ERAiNGWNKaPh1atcpNHAXgjjusff31zG876vzPRtIpBfnQAe2JIYW2bRO3ly6N37jvPjsy+Owzu9+qlY3UqZE1iscvfmHtH/6Q5gsrKmDJEpg/35ICWCVPkVqHXRk0bJht/777mEM/2rCKrU/azRLCM89kZ58Fbqut7C1bvTrz244+0PJwwFpB8MSQhzp2TNxetSp+o21bOOGExAO33GKnJQpgCGpT/f3vidvRFaxpqay0T50XXkjUJn/hBfs0Ouus5ge4dm3i0+2//7V1ZWXcy4mspi0b3XNb8/dR5KLLf+66K3Pb/OYb+9fYaKPEyGaXnu7doWtXTwx5Y//9rZQ8wIMPQptzTq35tap7d/sWet554YLMoQMPtLZZ49332suGgiafnxo3zt7XRndiJPnyS9h4Yzsy+fhjW9eqFTz9NJf+pooqyqmoaEa8JeSkk6wdMyZz27z6amt/9KPMbbPUiORBaYxUPdKFtmRiVNKECYmBK/vutmLD0soFXDitOTJeBPbMM2u+r2VlNjdqQ955Z8PKtB06qM6e/cNTohkl998/Q7EWuXXrNP1ikA3o1cu2+d57mdtmKTr3XCuPXlWV3f3go5Lqtno1/OxndvsAnuS51+MXpwHsuqvdLuDCac3x4x9bm7GOxKgYXbTh6mobItOmjY3squ2hh+witCFDEkdum21mh3bffmunk+KWL7e2SLt9Mq683JaqKvjuu8xsc8ECO3O4446Z2V6pisVg5Ur49NMw+/fEALRrZ+1R/IMniRcKKiuzToZsDNsoIC++aK2qzeKY0Q2rQp8+dn/NGhviuvHGdpL6ssvsd3D00YkhpwMH2mMLFljF0zrU85CrJRpSmomzo1OmWJ7v1av52yp1oTugSz4xdO0KaDXDeZYHiA/F+eUv7WtUEXcup2PwYGuPOSYLG//kE0sK0XzIS5faaKarr04ctR10kN3+4IM6h5yOGmWt9y+k55prrH300eZvK6ondtRRzd9WqdtuO2s9MQTwm9ijrF+ynH7M5kGOoqxDe/sAujFlQdeSFV3oV12dpdGfFRV2HmjOnJqV784/334fTzzR4Cai4qj77ZeF+IpYVEk3KvHVHK++am00F4ZruvbtYcstPTEE8db0DlTRgj9yNl0m3F1QE9HkWnTKIRqplBV9+9ow1FWrLAtFV0o1QvSru//+LMVWxKJTb9EXgKaoqrLfQevWfiovU0KOTCrpxHDe1k/xM5nACH3eZuxydYrqw1dV5WBaiTZtbMxeI61dm7jtH0rpGz7c2ub0M0SVygcObH48zsRiVgQ4mkgwl0o6MRw86yburT4xdBgFo3dva/faK2gYGzj3XGu9S6hpoktM3n236duILkkpkcrlORGL2RexECXYSjoxuPR89JG169eHn2EqWXT6KKunuYrYppvaAVpz6h1GsxseeWRmYnJhRyZ5YnCNVlFhlxAADBoUNpZk0Rh8719ouuj32pRxF4sX2+m8jTfObEylrl8/+5/zxODy3iefWLt2baIiRUjJ/QtePLXpzjnH2tuaUGIqGoWUPKOta77ychv04YnB5b2KisQ3w+hQN6SRI61Nrojr0hf1DaS6+Lwhjz9ubTQXhsucUCOTPDG4tC1YYO3q1WEnE4FE+Qs/t9085eV2xFVdDV9/nd5rv/zSXp+raTdKSSxm88z/UP4/R4IlBhHpJSIvishMEZkhIufF13cRkedEZHa87RwqRpdaRUWiPPmWW4aNJSqNHg2XdE23ww7WplMV/aWX7BrEaMSay6xQHdAhjxjWAxeo6rbAUOBsERkAXAxMUtV+wKT4fZdn5s+39rvvwl0X6P0LmXXTTdamc3V7VGb7RB/1nRUllxhUdaGqvhu/vQKYCfQEDgHujT/tXuDQIAG6enXsmDivv8UWYWKI5k7yi9oyY9gwa9NJ9G+9Ze3o0ZmPx9losc6dSygxJBOR3sAg4C2gu6ouBEsewCZ1vGakiEwWkcmLQ5/oLlHR2PXly5s3Br6pok7PaBpS13ydOln73HMNP3ftWisN3batH7FlS6hJe4InBhFpDzwCnK+qjf6uoqrjVXWwqg7uFs1R6HKqsjIxrfPmm+d+/9H0DE0ZYulS++lPrW3MrH1RKauo+q7LjlgMpk9PFBvOhaCJQURaYknhflWdEF/9lYj0iD/eA1gUKj7XsOnTrV20KLdHDckTy/i31cyJkmz0e63PPfdY+5vfZC8eZ4lhxQqYNy93+ww5KkmAu4CZqnpT0kOPA1FX1onAv3Mdm2u8vn0TlbJzOVwxOn3UoUPu9lkKOnWy+ZHWrUvMj1SXjz+2Ux1e6jy7QnRAhzxi2B04HthbRN6PLwcAY4DhIjIbGB6/7/LY229bG13fkAvRyJlTT83dPktFNJggmngnlU8/tcSxScoeQJdJ229vbUkkBlV9TVVFVQeq6o7x5SlVXaKq+6hqv3ib40s7XLp23BFatLDbSVMwZ1V02iqNKRtcI0UjjKLJj1K57DJrvXBh9nXsaMm6JBKDKy7RKJZc1E/K1MT1LrUzzrD2q6/qfs7TT1t71VXZj8flfmSSJwaXEXvtZeemIfuTtUTlL6KhlS7zWre2UTBz56Z+/OuvrW+pZ8+chlWyYjEbHp58UWc2eWJwGfOvf1mb7W82L75obTqlG1x6dtnF2lTvcXT9yNZb5y6eUheLWZ9ONCdKtnlicBlz2GGJo4Zdd83efqL+Ba/mmT23327tK69s+Ni111p7+um5i6fU5XpkkicGl1F/+5u1b76Zne3nuspkqYrFbCjqypUbPvbee9ZGczi47NtmGzt154nBFaTk8hQjRmR++1H/Qpcumd+2qyl6jx96KLFu9WpbOnRIjERz2deyJfTv74nBFbA//tHaxtTbSddrr1n7y19mftuupmOOsfaKKxLrfvc7a3fbLefhlLxcjkzyxOAyLvkUwxFHZHbb0aiMSy7J7Hbdhq6/3trZsxPr/vEPa5OThcuNWMzK3S9fnv19eWJwWXHlldY+8kjmtvnll5nblmtY69Z2uqiqCtassXWffWYDDIYODRtbKYo6oBtTx6q5PDG4rIiujAU45ZTMbPPww62N5px22RddyX7RRfaBVFUFPXqEjalU5XJkkicGlzWjRlkbVeFsrnfesdZPI+VOdMrowQcTtZOiBO1yq1cv2Gij3CQG0VwW+c6SwYMH6+TJk0OH4VIQsfa88+CWWzKzrSL4ky0oIrZ06gTLlsGSJT4qLJRhw+x38eqrmdmeiExR1Q1m1PAjBpdVJ59s7a23Nm87n33W/Fhc07RrZ8l42TKoqPCkEFI0MinbX448MbisSq7QmdzvkK5odJOXec69PfdM3B4wIFwczhLDN9/A559ndz+eGFzW/fzn1l59ddO3EV1tG42jd7kzdmzi9rnnhovD5a4D2hODy7rkK2dvuqnu59Unmk3M6/PkXu/eif6d448PGkrJy9WkPZ4YXE5E5TEuuCD91374obXRh5PLvfHj4YYbvAxGaJ07Q2Vl9hNDeXY375x55pnEB/tf/wonndT41x57rLU+fj6c004LHYGLDBxYxEcMInK3iCwSkelJ664QkQW15oB2RWL33a1Nd57mGTOsHeOzfztHLAYzZ8K6ddnbR8hTSX8F9k+x/ubkOaBzHJPLoqgAXnU1PPpo418X9S/4+W3nLDGsWwf/+1/29hEsMajqK4BX1y8xO+5obWOL602daq33LzhncjEyKR87n88RkanxU02d63qSiIwUkckiMnnx4sW5jM81QzTstLo6MUVnfaL+BZ9b2DnTvz+Ul5dWYhgH9AV2BBYCN9b1RFUdr6qDVXVwt27dchSey4R+/awdPrzh586caW1Th7k6V2xatbIZ3UomMajqV6paparVwF+AXULH5DIvOjdaVZUojFeX6mpro5nbnHPZn7QnrxKDiCQPSDwMyEHlcRdCr17WRiOVUnnjDWu9f8G5mmIxmDsXVqzIzvZDDlf9B/AGsI2IfC4ipwLXicg0EZkK7AWMChWfy65oVrB16xIXsNUWXeuw+eY5Ccm5gpHtSXuCXeCmqsekWH1XzgNxQVRUWEG8RYtg551tgvna5syx9s9/zm1szuW75JFJu+6a+e3n1akkV1qiUtpr1qSuFhn1L+y3X+5icq4QbLEFdOiQvX4GTwwumIoKq/0CNsoi2QsvWFvmf6HObUDECup5YnBFae5ca1etgm+/TawfOdLaPn1yHpJzBSGbk/Z4YnBBdexoh8SQGKkE8Omn1o4fn/uYnCsEsRgsXQoLF2Z+254YXHAff2ztt98mjhqi/oW99w4Tk3P5LpulMTwxuOC6dYO2be12nz4wcaLd9v4F5+o2aBA8+KC1meb/ei4vzJpl7dKlcPbZdjsqneGc21DHjnDUUdmZB90Tg8sLlZU2SgkSw1jvuSdcPM6VMk8MLm+8+27N+9m4cMc51zBPDC5vDBgALVvaba+P5Fw4nhhcXvnvf609JlXBFOdcTgSrleRcKkOGZOeCHedc4/kRg3POuRo8MTjnnKvBE4NzzrkaPDE455yrwRODc865GjwxOOecq8ETg3POuRo8MTjnnKtBtAiuJhKRxcC8Jr68K/B1BsMpdP5+JPh7UZO/HzUVw/uxhap2q72yKBJDc4jIZFUdHDqOfOHvR4K/FzX5+1FTMb8ffirJOedcDZ4YnHPO1eCJAXy6+Zr8/Ujw96Imfz9qKtr3o+T7GJxzztXkRwzOOedq8MTgnHOuhpJODCKyv4jMEpE5InJx6HhCEZFeIvKiiMwUkRkicl7omPKBiLQQkfdEZGLoWEITkU4i8i8R+Sj+d1KyM3KLyKj4/8l0EfmHiLQOHVOmlWxiEJEWwB3AT4ABwDEiMiBsVMGsBy5Q1W2BocDZJfxeJDsPmBk6iDxxK/C0qvYHdqBE3xcR6QmcCwxW1e2BFsDRYaPKvJJNDMAuwBxV/URV1wIPAocEjikIVV2oqu/Gb6/A/ul7ho0qLBGpBA4E7gwdS2gi0hHYE7gLQFXXquryoEGFVQ60EZFyoC3wReB4Mq6UE0NPYH7S/c8p8Q9DABHpDQwC3gocSmi3AKOB6sBx5IMtgcXAPfFTa3eKSLvQQYWgqguAG4DPgIXAN6r6bNioMq+UE4OkWFfSY3dFpD3wCHC+qn4bOp5QROQgYJGqTgkdS54oB3YCxqnqIGAlUJJ9ciLSGTuz0AfYDGgnIseFjSrzSjkxfA70SrpfSREeEjaWiLTEksL9qjohdDyB7Q4cLCJzsVOMe4vI38OGFNTnwOeqGh1F/gtLFKVoX+BTVV2squuACcBugWPKuFJODO8A/USkj4i0wjqQHg8cUxAiItj545mqelPoeEJT1V+raqWq9sb+Ll5Q1aL7VthYqvolMF9Etomv2gf4MGBIIX0GDBWRtvH/m30owo748tABhKKq60XkHOAZbGTB3ao6I3BYoewOHA9ME5H34+t+o6pPhQvJ5Zn/H7g//iXqE+DkwPEEoapvici/gHex0XzvUYSlMbwkhnPOuRpK+VSSc865FDwxOOecq8ETg3POuRo8MTjnnKvBE4NzzrkaPDE455yrwRODK3kisqWIjI+XlF4lIstE5EMRuVdE9kp63hUicmjAUJ3LiZK9wM05ABEZDLwMrAP+BswA2gBbAz8FVgAvxp9+OXAv8FjOA3UuhzwxuFJ3OVY6eZCqvp/8QPzK+E1DBOVcSH4qyZW6fsCS2kkBQFWrVfULEektIlGJgBNFRKMl+fkisq+IPCsiy0VkjYhMFZEzam9XROaKyEsispOIvCAi34nI0vipq01qPbd1/BTWrPhpruUiMk1Ers/ge+BcDX7E4Erdx8A2IvKzeqrKLsZqSd0HvEqK2jgiMhL4E/Am8HusNPVwYJyI9FXVi2q9pBKYhFW0jaqVngIMFpEhqroq/rw74uv/BtyM1fXqB+zdtB/XuYZ5rSRX0uJzF78MtARmA69hlXdfUtWZtZ6rwL2qelKt9T2AT4EJqnpsrcduBc4BtlbVj+Pr5gJbAKNU9Zak544CbgJ+rapj4uuWAm+q6gEZ+pGda5CfSnIlTVXfAHbGOpU3wqqGjgU+FJFXRWTLRmzmCKACuEtEuiYvwBPY/9k+tV7zLTCu1rqx8fWHJa37BthORLZP80dzrsn8VJIreao6DTgJQES2AH4EnAbsAfxbRHaOzwtel23j7fP1PKd7rfufqOr3teL4XkQ+wabSjJyPncKaFn/sRSzZPKGqPu2oywpPDM4lUdV5wN9EJOpP2B3YBTvFVJdomtgTsHmAU/mk9q4a2FYUz7/j83AfgCWsfYFTgVdFZN8GEpZzTeKJwbkUVFVF5C0sMfRs4Omz4+3XqlrfUUOyviLSKvmDXUQqsLmEP6oVy1Lg78Df47OGjQFGY3MP/7OR+3Ou0byPwZU0ERkuIht8QRKRNsCI+N1oGsvvgC4pNvMw8D1wZfx1tbe1UfxDP1lH4Kxa686Kr38s/roWItIp+Qlqo0Xei99NFYtzzeajklxJE5HpwMbYfN/TgFVAL+BY7Ornv6nqifHnPocdQVyJzf2rqvpg/LGTgTuB+VifwDygGxADDgUGqOrc+HPnYtNCbowNV52CdYCfAswCBqvqynhSWBiP7T1gEXZEcSb2pW57Vf0iG++LK22eGFxJE5ER2CmZYdgpo07YSKCp2Af8X6NOXhHph11XMBToAKCqkrSt3YELseTRCfga+6CfCNyhqmviz5sLzAV+CdwA/H/A2vjzLlTVr+LPa4UloX2AvkB7LFG8APxBVaNTWM5llCcG53IsSgyq+uPAoTiXkvcxOOecq8ETg3POuRo8MTjnnKvB+xicc87V4EcMzjnnavDE4JxzrgZPDM4552rwxOCcc64GTwzOOedq+H+LUfyEpkrwDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env_name = 'CartPole-v1'\n",
    "    agent = DQNAgent(env_name)\n",
    "    agent.run()\n",
    "    #agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save('ddqn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/10, score: 154\n",
      "episode: 1/10, score: 143\n",
      "episode: 2/10, score: 154\n",
      "episode: 3/10, score: 145\n",
      "episode: 4/10, score: 142\n",
      "episode: 5/10, score: 144\n",
      "episode: 6/10, score: 140\n",
      "episode: 7/10, score: 148\n",
      "episode: 8/10, score: 144\n",
      "episode: 9/10, score: 140\n",
      "episode: 10/10, score: 155\n",
      "episode: 11/10, score: 146\n",
      "episode: 12/10, score: 152\n",
      "episode: 13/10, score: 151\n",
      "episode: 14/10, score: 151\n",
      "episode: 15/10, score: 146\n",
      "episode: 16/10, score: 148\n",
      "episode: 17/10, score: 155\n",
      "episode: 18/10, score: 151\n",
      "episode: 19/10, score: 149\n",
      "episode: 20/10, score: 147\n",
      "episode: 21/10, score: 147\n",
      "episode: 22/10, score: 158\n",
      "episode: 23/10, score: 149\n",
      "episode: 24/10, score: 151\n",
      "episode: 25/10, score: 150\n",
      "episode: 26/10, score: 152\n",
      "episode: 27/10, score: 146\n",
      "episode: 28/10, score: 155\n",
      "episode: 29/10, score: 148\n",
      "episode: 30/10, score: 150\n",
      "episode: 31/10, score: 147\n",
      "episode: 32/10, score: 150\n",
      "episode: 33/10, score: 141\n",
      "episode: 34/10, score: 149\n",
      "episode: 35/10, score: 150\n",
      "episode: 36/10, score: 152\n",
      "episode: 37/10, score: 142\n",
      "episode: 38/10, score: 146\n",
      "episode: 39/10, score: 143\n",
      "episode: 40/10, score: 147\n",
      "episode: 41/10, score: 143\n",
      "episode: 42/10, score: 150\n",
      "episode: 43/10, score: 146\n",
      "episode: 44/10, score: 143\n",
      "episode: 45/10, score: 147\n",
      "episode: 46/10, score: 150\n",
      "episode: 47/10, score: 157\n",
      "episode: 48/10, score: 148\n",
      "episode: 49/10, score: 146\n",
      "episode: 50/10, score: 149\n",
      "episode: 51/10, score: 146\n",
      "episode: 52/10, score: 150\n",
      "episode: 53/10, score: 146\n",
      "episode: 54/10, score: 157\n",
      "episode: 55/10, score: 146\n",
      "episode: 56/10, score: 142\n",
      "episode: 57/10, score: 144\n",
      "episode: 58/10, score: 148\n",
      "episode: 59/10, score: 144\n",
      "episode: 60/10, score: 157\n",
      "episode: 61/10, score: 143\n",
      "episode: 62/10, score: 145\n",
      "episode: 63/10, score: 142\n",
      "episode: 64/10, score: 143\n",
      "episode: 65/10, score: 146\n",
      "episode: 66/10, score: 152\n",
      "episode: 67/10, score: 148\n",
      "episode: 68/10, score: 143\n",
      "episode: 69/10, score: 156\n",
      "episode: 70/10, score: 152\n",
      "episode: 71/10, score: 150\n",
      "episode: 72/10, score: 148\n",
      "episode: 73/10, score: 154\n",
      "episode: 74/10, score: 147\n",
      "episode: 75/10, score: 146\n",
      "episode: 76/10, score: 147\n",
      "episode: 77/10, score: 147\n",
      "episode: 78/10, score: 146\n",
      "episode: 79/10, score: 143\n",
      "episode: 80/10, score: 150\n",
      "episode: 81/10, score: 151\n",
      "episode: 82/10, score: 146\n",
      "episode: 83/10, score: 147\n",
      "episode: 84/10, score: 145\n",
      "episode: 85/10, score: 137\n",
      "episode: 86/10, score: 148\n",
      "episode: 87/10, score: 146\n",
      "episode: 88/10, score: 145\n",
      "episode: 89/10, score: 146\n",
      "episode: 90/10, score: 143\n",
      "episode: 91/10, score: 156\n",
      "episode: 92/10, score: 148\n",
      "episode: 93/10, score: 144\n",
      "episode: 94/10, score: 144\n",
      "episode: 95/10, score: 138\n",
      "episode: 96/10, score: 149\n",
      "episode: 97/10, score: 146\n",
      "episode: 98/10, score: 152\n",
      "episode: 99/10, score: 145\n"
     ]
    }
   ],
   "source": [
    "agent.load('ddqn.h5')\n",
    "for e in range(100):\n",
    "    state = agent.env.reset()\n",
    "    state = np.reshape(state, [1, agent.state_size])\n",
    "    done = False\n",
    "    i = 0\n",
    "    while not done:\n",
    "        #agent.env.render()\n",
    "        action = np.argmax(agent.model.predict(state))\n",
    "        next_state, reward, done, _ = agent.env.step(action)\n",
    "        state = np.reshape(next_state, [1, agent.state_size])\n",
    "        i += 1\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}\".format(e, agent.EPISODES, i))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
