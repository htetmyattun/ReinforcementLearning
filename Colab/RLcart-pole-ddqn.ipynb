{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RLcart-pole-ddqn.ipynb","provenance":[],"authorship_tag":"ABX9TyMHbsxoz5Z1qGPiX0sm5bfw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SVkZprG_PKoF","executionInfo":{"status":"ok","timestamp":1601978024813,"user_tz":-480,"elapsed":3433,"user":{"displayName":"altotech aitraining","photoUrl":"","userId":"00866022040909509342"}}},"source":["# Tutorial by www.pylessons.com\n","# Tutorial written for - Tensorflow 1.15, Keras 2.2.4\n","\n","import os\n","import random\n","import gym\n","import pylab\n","import numpy as np\n","from collections import deque\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, Lambda, Add\n","from keras.optimizers import Adam, RMSprop\n","from keras import backend as K"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_8vJeQAU2fW","executionInfo":{"status":"ok","timestamp":1601978024817,"user_tz":-480,"elapsed":3394,"user":{"displayName":"altotech aitraining","photoUrl":"","userId":"00866022040909509342"}}},"source":["def OurModel(input_shape, action_space, dueling):\n","    X_input = Input(input_shape)\n","    X = X_input\n","\n","    # 'Dense' is the basic form of a neural network layer\n","    # Input Layer of state size(4) and Hidden Layer with 512 nodes\n","    X = Dense(512, input_shape=input_shape, activation=\"relu\", kernel_initializer='he_uniform')(X)\n","\n","    # Hidden layer with 256 nodes\n","    X = Dense(256, activation=\"relu\", kernel_initializer='he_uniform')(X)\n","    \n","    # Hidden layer with 64 nodes\n","    X = Dense(64, activation=\"relu\", kernel_initializer='he_uniform')(X)\n","\n","    if dueling:\n","        state_value = Dense(1, kernel_initializer='he_uniform')(X)\n","        state_value = Lambda(lambda s: K.expand_dims(s[:, 0], -1), output_shape=(action_space,))(state_value)\n","\n","        action_advantage = Dense(action_space, kernel_initializer='he_uniform')(X)\n","        action_advantage = Lambda(lambda a: a[:, :] - K.mean(a[:, :], keepdims=True), output_shape=(action_space,))(action_advantage)\n","\n","        X = Add()([state_value, action_advantage])\n","    else:\n","        # Output Layer with # of actions: 2 nodes (left, right)\n","        X = Dense(action_space, activation=\"linear\", kernel_initializer='he_uniform')(X)\n","\n","    model = Model(inputs = X_input, outputs = X, name='CartPole Dueling DDQN model')\n","    model.compile(loss=\"mean_squared_error\", optimizer=RMSprop(lr=0.00025, rho=0.95, epsilon=0.01), metrics=[\"accuracy\"])\n","\n","    model.summary()\n","    return model"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cSRzdjCU6Wf","executionInfo":{"status":"ok","timestamp":1601978024824,"user_tz":-480,"elapsed":3394,"user":{"displayName":"altotech aitraining","photoUrl":"","userId":"00866022040909509342"}},"outputId":"dda22cbd-5c72-48e3-8a7f-80def6be3382","colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["class DQNAgent:\n","    def __init__(self, env_name):\n","        self.env_name = env_name       \n","        self.env = gym.make(env_name)\n","        self.env.seed(0)  \n","        # by default, CartPole-v1 has max episode steps = 500\n","        self.env._max_episode_steps = 4000\n","        self.state_size = self.env.observation_space.shape[0]\n","        self.action_size = self.env.action_space.n\n","\n","        self.EPISODES = 100000\n","        self.memory = deque(maxlen=2000)\n","        \n","        self.gamma = 0.95    # discount rate\n","        self.epsilon = 1.0  # exploration rate\n","        self.epsilon_min = 0.01 # minimum exploration probability\n","        self.epsilon_decay = 0.999 # exponential decay rate for exploration prob\n","        self.batch_size = 32 \n","        self.train_start = 1000\n","\n","        # defining model parameters\n","        self.ddqn = True # use doudle deep q network\n","        self.Soft_Update = False # use soft parameter update\n","        self.dueling = True # use dealing netowrk\n","\n","        self.TAU = 0.1 # target network soft update hyperparameter\n","\n","        self.Save_Path = 'Models'\n","        if not os.path.exists(self.Save_Path): os.makedirs(self.Save_Path)\n","        self.scores, self.episodes, self.average = [], [], []\n","        \n","        if self.ddqn:\n","            print(\"----------Double DQN--------\")\n","            self.Model_name = os.path.join(self.Save_Path,\"Dueling DDQN_\"+self.env_name+\".h5\")\n","        else:\n","            print(\"-------------DQN------------\")\n","            self.Model_name = os.path.join(self.Save_Path,\"Dueling DQN_\"+self.env_name+\".h5\")\n","        \n","        # create main model and target model\n","        self.model = OurModel(input_shape=(self.state_size,), action_space = self.action_size, dueling = self.dueling)\n","        self.target_model = OurModel(input_shape=(self.state_size,), action_space = self.action_size, dueling = self.dueling)\n","\n","    # after some time interval update the target model to be same with model\n","    def update_target_model(self):\n","        if not self.Soft_Update and self.ddqn:\n","            self.target_model.set_weights(self.model.get_weights())\n","            return\n","        if self.Soft_Update and self.ddqn:\n","            q_model_theta = self.model.get_weights()\n","            target_model_theta = self.target_model.get_weights()\n","            counter = 0\n","            for q_weight, target_weight in zip(q_model_theta, target_model_theta):\n","                target_weight = target_weight * (1-self.TAU) + q_weight * self.TAU\n","                target_model_theta[counter] = target_weight\n","                counter += 1\n","            self.target_model.set_weights(target_model_theta)\n","\n","    def remember(self, state, action, reward, next_state, done):\n","        self.memory.append((state, action, reward, next_state, done))\n","        if len(self.memory) > self.train_start:\n","            if self.epsilon > self.epsilon_min:\n","                self.epsilon *= self.epsilon_decay\n","\n","    def act(self, state):\n","        if np.random.random() <= self.epsilon:\n","            return random.randrange(self.action_size)\n","        else:\n","            return np.argmax(self.model.predict(state))\n","\n","    def replay(self):\n","        if len(self.memory) < self.train_start:\n","            return\n","        # Randomly sample minibatch from the memory\n","        minibatch = random.sample(self.memory, self.batch_size)\n","\n","        state = np.zeros((self.batch_size, self.state_size))\n","        next_state = np.zeros((self.batch_size, self.state_size))\n","        action, reward, done = [], [], []\n","\n","        # do this before prediction\n","        # for speedup, this could be done on the tensor level\n","        # but easier to understand using a loop\n","        for i in range(self.batch_size):\n","            state[i] = minibatch[i][0]\n","            action.append(minibatch[i][1])\n","            reward.append(minibatch[i][2])\n","            next_state[i] = minibatch[i][3]\n","            done.append(minibatch[i][4])\n","\n","        # do batch prediction to save speed\n","        # predict Q-values for starting state using the main network\n","        target = self.model.predict(state)\n","        # predict best action in ending state using the main network\n","        target_next = self.model.predict(next_state)\n","        # predict Q-values for ending state using the target network\n","        target_val = self.target_model.predict(next_state)\n","\n","        for i in range(len(minibatch)):\n","            # correction on the Q value for the action used\n","            if done[i]:\n","                target[i][action[i]] = reward[i]\n","            else:\n","                if self.ddqn: # Double - DQN\n","                    # current Q Network selects the action\n","                    # a'_max = argmax_a' Q(s', a')\n","                    a = np.argmax(target_next[i])\n","                    # target Q Network evaluates the action\n","                    # Q_max = Q_target(s', a'_max)\n","                    target[i][action[i]] = reward[i] + self.gamma * (target_val[i][a])   \n","                else: # Standard - DQN\n","                    # DQN chooses the max Q value among next actions\n","                    # selection and evaluation of action is on the target Q Network\n","                    # Q_max = max_a' Q_target(s', a')\n","                    target[i][action[i]] = reward[i] + self.gamma * (np.amax(target_next[i]))\n","\n","        # Train the Neural Network with batches\n","        self.model.fit(state, target, batch_size=self.batch_size, verbose=0)\n","\n","    def load(self, name):\n","        self.model = load_model(name)\n","\n","    def save(self, name):\n","        self.model.save(name)\n","\n","    pylab.figure(figsize=(18, 9))\n","    def PlotModel(self, score, episode):\n","        self.scores.append(score)\n","        self.episodes.append(episode)\n","        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n","        pylab.plot(self.episodes, self.average, 'r')\n","        pylab.plot(self.episodes, self.scores, 'b')\n","        pylab.ylabel('Score', fontsize=18)\n","        pylab.xlabel('Steps', fontsize=18)\n","        dqn = 'DQN_'\n","        softupdate = ''\n","        dueling = ''\n","        if self.ddqn: dqn = 'DDQN_'\n","        if self.Soft_Update: softupdate = '_soft'\n","        if self.dueling: dueling = '_Dueling'\n","        try:\n","            pylab.savefig(dqn+self.env_name+softupdate+dueling+\".png\")\n","        except OSError:\n","            pass\n","\n","        return str(self.average[-1])[:5]\n","    \n","    def run(self):\n","        for e in range(self.EPISODES):\n","            state = self.env.reset()\n","            state = np.reshape(state, [1, self.state_size])\n","            done = False\n","            i = 0\n","            while not done:\n","                #self.env.render()\n","                action = self.act(state)\n","                next_state, reward, done, _ = self.env.step(action)\n","                next_state = np.reshape(next_state, [1, self.state_size])\n","                if not done or i == self.env._max_episode_steps-1:\n","                    reward = reward\n","                else:\n","                    reward = -100\n","                self.remember(state, action, reward, next_state, done)\n","                state = next_state\n","                i += 1\n","                if done:\n","                    # every step update target model\n","                    self.update_target_model()\n","                    \n","                    # every episode, plot the result\n","                    average = self.PlotModel(i, e)\n","                     \n","                    print(\"episode: {}/{}, score: {}, e: {:.2}, average: {}\".format(e, self.EPISODES, i, self.epsilon, average))\n","                    if i == self.env._max_episode_steps:\n","                        print(\"Saving trained model as\", self.Model_name)\n","                        #self.save(self.Model_name)\n","                        break\n","                self.replay()\n","\n","    def test(self):\n","        self.load('ddqn.h5')\n","        for e in range(self.EPISODES):\n","            state = self.env.reset()\n","            state = np.reshape(state, [1, self.state_size])\n","            done = False\n","            i = 0\n","            while not done:\n","                self.env.render()\n","                action = np.argmax(self.model.predict(state))\n","                next_state, reward, done, _ = self.env.step(action)\n","                state = np.reshape(next_state, [1, self.state_size])\n","                i += 1\n","                if done:\n","                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, i))\n","                    break\n","\n"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1296x648 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HAYPn6_BU682","executionInfo":{"status":"error","timestamp":1601978031433,"user_tz":-480,"elapsed":9988,"user":{"displayName":"altotech aitraining","photoUrl":"","userId":"00866022040909509342"}},"outputId":"5a28f24a-7fb1-48f9-9e79-a7997cc3173e","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == \"__main__\":\n","    env_name = 'CartPole-v1'\n","    agent = DQNAgent(env_name)\n","    agent.run()\n","    #agent.test()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["----------Double DQN--------\n","Model: \"CartPole Dueling DDQN model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 4)]          0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 512)          2560        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           16448       dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1)            65          dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 2)            130         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 1)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 2)            0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 2)            0           lambda[0][0]                     \n","                                                                 lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 150,531\n","Trainable params: 150,531\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"CartPole Dueling DDQN model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 4)]          0                                            \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 512)          2560        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 256)          131328      dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 64)           16448       dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            65          dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 2)            130         dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 1)            0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 2)            0           dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 2)            0           lambda_2[0][0]                   \n","                                                                 lambda_3[0][0]                   \n","==================================================================================================\n","Total params: 150,531\n","Trainable params: 150,531\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","episode: 0/100000, score: 10, e: 1.0, average: 10.0\n","episode: 1/100000, score: 30, e: 1.0, average: 20.0\n","episode: 2/100000, score: 13, e: 1.0, average: 17.66\n","episode: 3/100000, score: 15, e: 1.0, average: 17.0\n","episode: 4/100000, score: 59, e: 1.0, average: 25.4\n","episode: 5/100000, score: 19, e: 1.0, average: 24.33\n","episode: 6/100000, score: 17, e: 1.0, average: 23.28\n","episode: 7/100000, score: 14, e: 1.0, average: 22.12\n","episode: 8/100000, score: 13, e: 1.0, average: 21.11\n","episode: 9/100000, score: 19, e: 1.0, average: 20.9\n","episode: 10/100000, score: 16, e: 1.0, average: 20.45\n","episode: 11/100000, score: 10, e: 1.0, average: 19.58\n","episode: 12/100000, score: 17, e: 1.0, average: 19.38\n","episode: 13/100000, score: 32, e: 1.0, average: 20.28\n","episode: 14/100000, score: 19, e: 1.0, average: 20.2\n","episode: 15/100000, score: 24, e: 1.0, average: 20.43\n","episode: 16/100000, score: 51, e: 1.0, average: 22.23\n","episode: 17/100000, score: 14, e: 1.0, average: 21.77\n","episode: 18/100000, score: 17, e: 1.0, average: 21.52\n","episode: 19/100000, score: 21, e: 1.0, average: 21.5\n","episode: 20/100000, score: 28, e: 1.0, average: 21.80\n","episode: 21/100000, score: 16, e: 1.0, average: 21.54\n","episode: 22/100000, score: 19, e: 1.0, average: 21.43\n","episode: 23/100000, score: 12, e: 1.0, average: 21.04\n","episode: 24/100000, score: 34, e: 1.0, average: 21.56\n","episode: 25/100000, score: 11, e: 1.0, average: 21.15\n","episode: 26/100000, score: 13, e: 1.0, average: 20.85\n","episode: 27/100000, score: 32, e: 1.0, average: 21.25\n","episode: 28/100000, score: 16, e: 1.0, average: 21.06\n","episode: 29/100000, score: 14, e: 1.0, average: 20.83\n","episode: 30/100000, score: 16, e: 1.0, average: 20.67\n","episode: 31/100000, score: 17, e: 1.0, average: 20.56\n","episode: 32/100000, score: 13, e: 1.0, average: 20.33\n","episode: 33/100000, score: 21, e: 1.0, average: 20.35\n","episode: 34/100000, score: 20, e: 1.0, average: 20.34\n","episode: 35/100000, score: 14, e: 1.0, average: 20.16\n","episode: 36/100000, score: 30, e: 1.0, average: 20.43\n","episode: 37/100000, score: 51, e: 1.0, average: 21.23\n","episode: 38/100000, score: 12, e: 1.0, average: 21.0\n","episode: 39/100000, score: 12, e: 1.0, average: 20.77\n","episode: 40/100000, score: 17, e: 1.0, average: 20.68\n","episode: 41/100000, score: 12, e: 1.0, average: 20.47\n","episode: 42/100000, score: 40, e: 1.0, average: 20.93\n","episode: 43/100000, score: 9, e: 1.0, average: 20.65\n","episode: 44/100000, score: 17, e: 1.0, average: 20.57\n","episode: 45/100000, score: 32, e: 1.0, average: 20.82\n","episode: 46/100000, score: 27, e: 1.0, average: 20.95\n","episode: 47/100000, score: 8, e: 1.0, average: 20.68\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e4782bd19ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0menv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CartPole-v1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#agent.test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-376346e9b006>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0;31m#self.save(self.Model_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-376346e9b006>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# do batch prediction to save speed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# predict Q-values for starting state using the main network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;31m# predict best action in ending state using the main network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtarget_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:980 __call__\n        with ops.name_scope_v2(name_scope):\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:6631 __enter__\n        scope_name = scope.__enter__()\n    /usr/lib/python3.6/contextlib.py:81 __enter__\n        return next(self.gen)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:4190 name_scope\n        raise ValueError(\"'%s' is not a valid scope name\" % name)\n\n    ValueError: 'CartPole Dueling DDQN model/' is not a valid scope name\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}